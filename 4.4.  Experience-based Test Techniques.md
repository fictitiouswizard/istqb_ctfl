Commonly used experience-based test techniques discussed in the following sections are:

* Error guessing
* Exploratory testing
* Checklist-based testing

## 4.4.1 Error Guessing

Error guessing is a test technique used to anticipate the occurrence of errors, defects, and failures, based on the tester's knowledge, including:

* How the application has worked in the past
* The types of errors the developers tend to make and the types of defects that result from these errors
* The types of failures that have occurred in other, similar applications

In general, errors, defects and failures may be related to: input (e.g., correct input not accepted, parameters wrong or missing), output (e.g., wrong format, wrong result), logic (e.g., missing cases, wrong operator), computation (e.g., incorrect operand, wrong computation), interfaces (e.g., parameter mismatch, incompatible types), or data (e.g., incorrect initialization, wrong type).

Fault attacks are a way to implement error guessing.  This test technique requires the tester to create or acquire a list of possible errors, defects and failures, and to design tests that will identify defects associated with the errors, expose the defects, or cause the failures.  These lists can be built based on experience, defect and failure data, or from common knowledge about why software fails.

See (Whitaker 2002, Whittaker 2003, Andrews 2006) for more information on error guessing and fault attacks.

## 4.4.2 Exploratory Testing

In exploratory testing, tests are simultaneously designed, executed, and evaluated while the tester learns about the test object.  The testing is used to learn more about the test object, to explore it more deeply with focused tests, and to create tests for untested areas.

Exploratory testing is sometimes performed using session-based testing to structure the testing.  In a session-based approach, exploratory testing is performed within a defined time box.  The tester uses a test charter containing test objectives to guide the testing.  The test session is usually followed by a debriefing that involves a discussion between the tester and stakeholders interested in the test results of the test session.  In this approach test objectives may be treated as high-level test conditions.  Coverage items are identified and exercised during the test session.  The tester bay use test session sheets to document the steps followed and the discoveries made.

Exploratory testing is useful when there are few or inadequate specifications or there is significant time pressure on testing.  Exploratory testing is also useful to complement other more formal test techniques.  Exploratory testing will be more effective if the tester is experienced , has domain knowledge and has a high degree of essential skills, like analytical skills, curiousity and creativeness (see section 1.5.1).

Exploratory testing can incorporate the use of other test techniques (e.g., equivalence partitioning).  More information about exploratory testing can be found in (Kaner 1999, Whittaker 2009, Hendrickson 2013).

## 4.4.3. Checklist-Based Testing

In checklist-based testing, a tester designs, implements, and executes tests to cover test conditions from a checklist.  Checklists can be built based on experience, knowledge about what is important for the user, or an understanding of why and how software fails.  Checklists should not contain items that can be checked automatically, items better suited as entry criteria, exit criteria, or items that are to general (Brykczynki 1999).

Checklist items are often phrased in the form of a question.  It should be possible to check each item separately and directly.  These items may refer to requirements, graphical interface properties, quality characteristics or other forms of test conditions.  Checklists can be created to support various test types, including functional and non-functional testing (e.g., 10 heuristics for usability testing (Nielsen 1994)).

Some checklist entries may gradually become less effective over time because the developers will learn to avoid making the same errors.  New entries may also need to be added to reflect newly found high severity defects.  Therefor, checklists should be regularly  updated based on defect analysis.  However, care should be taken to avoid letting the checklist become too long (Gawande 2009).

In the absence of detailed test cases, checklist-based testing can provide guidelines and some degree of consistency for the testing.  If the checklists are high-level, some variability in the actual testing is likely to occur, resulting in potentially greater coverage buy less repeatability.